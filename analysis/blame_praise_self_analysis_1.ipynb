{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25a7b623",
   "metadata": {},
   "source": [
    "# Set Up Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df386216",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# IMPORT #\n",
    "##########\n",
    "\n",
    "# Data processing and math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Statistics\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols, mixedlm\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Display handling\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "#################\n",
    "# CONFIGURATION #\n",
    "#################\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore', category = UserWarning)\n",
    "warnings.filterwarnings('ignore', category = RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', category = ConvergenceWarning)\n",
    "\n",
    "# Configure display\n",
    "display(HTML(\"<style>.output_scroll { height: auto !important; max-height: none !important; }</style>\"))\n",
    "\n",
    "# Set global plotting style\n",
    "sns.set_theme(style = \"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "##########\n",
    "# LABELS #\n",
    "##########\n",
    "labels_measure = {\n",
    "    'measure_action':  'Responsibility for Action',\n",
    "    'measure_beliefs': 'Responsibility for Character',\n",
    "    'measure_self':    'True Self'\n",
    "}\n",
    "\n",
    "labels_gender = {\n",
    "    '1': 'Female',\n",
    "    '2': 'Male',\n",
    "    '3': 'Non-binary',\n",
    "    '4': 'Prefer not to say'\n",
    "}\n",
    "\n",
    "labels_education = {\n",
    "    '1': 'Less than high school',\n",
    "    '2': 'High school diploma or equivalent',\n",
    "    '3': 'Associate degree (e.g., AA or AS)',\n",
    "    '4': 'Bachelor’s degree (e.g., BA or BSC)',\n",
    "    '5': 'Master’s degree (e.g., MA or MSc)',\n",
    "    '6': 'Professional degree (e.g., JD or MD)',\n",
    "    '7': 'Doctorate (e.g., PhD or EdD)'\n",
    "}\n",
    "\n",
    "\n",
    "#################\n",
    "# VISUALIZATION #\n",
    "#################\n",
    "palette_main = {\n",
    "    \"Good\": \"#0072B2\", \"Bad\": \"#D55E00\",\n",
    "    \"Reflected\": \"#009E73\", \"Unreflected\": \"#CC79A7\",\n",
    "    \"Activist\": \"#56B4E9\", \"Bigot\": \"#E69F00\",\n",
    "    \"Help\": \"#F0E442\", \"Harm\": \"#882255\"\n",
    "}\n",
    "\n",
    "palette_context = [\"#0072B2\", \"#D55E00\", \"#009E73\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b1ea54",
   "metadata": {},
   "source": [
    "# Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb99460",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('blame_praise_self_data_1.csv')\n",
    "\n",
    "# Define factors\n",
    "def get_factors(n):\n",
    "    idx = n - 1\n",
    "    upbringing = \"Good\" if (idx >> 3) & 1 else \"Bad\"\n",
    "    reflection = \"Reflected\" if (idx >> 2) & 1 else \"Unreflected\"\n",
    "    belief = \"Bigot\" if (idx >> 1) & 1 else \"Activist\"\n",
    "    valence = \"Harm\" if idx & 1 else \"Help\"\n",
    "    return upbringing, reflection, belief, valence\n",
    "\n",
    "# Reshape wide to long\n",
    "contexts = ['homophobia', 'racism', 'sexism']\n",
    "measure_mapping = {'pAction': 'measure_action', 'pBeliefs': 'measure_beliefs', 'agreement': 'measure_self'}\n",
    "long_data = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    p_id = row['ID']\n",
    "    for ctx in contexts:\n",
    "        for i in range(1, 17):\n",
    "            col_base = f'{ctx}.{i}'\n",
    "            if f'{col_base}-pAction' in df.columns and pd.notna(row[f'{col_base}-pAction']):\n",
    "                up_f, refl_f, bel_f, val_f = get_factors(i)\n",
    "                trial_data = {\n",
    "                    'ID': p_id, 'Context': ctx, 'Upbringing': up_f, \n",
    "                    'Reflection': refl_f, 'Belief': bel_f, 'Action': val_f\n",
    "                }\n",
    "                for old_suffix, new_name in measure_mapping.items():\n",
    "                    val = pd.to_numeric(row[f'{col_base}-{old_suffix}'], errors='coerce')\n",
    "                    \n",
    "                    # Center scale\n",
    "                    trial_data[new_name] = val - 7 if pd.notna(val) else np.nan\n",
    "                long_data.append(trial_data)\n",
    "\n",
    "df_long = pd.DataFrame(long_data).dropna(subset=['measure_action'])\n",
    "\n",
    "# Create DataFrames\n",
    "demo_cols = ['ID', 'Gender', 'Age', 'Education', 'politics', 'determinism', 'freeWill']\n",
    "df_robust = df_long.merge(df[demo_cols], on = 'ID', how = 'left')\n",
    "\n",
    "# Rename variables\n",
    "df_robust = df_robust.rename(columns={\n",
    "    'politics':    'Political_Orientation', \n",
    "    'determinism': 'Social_Determinism', \n",
    "    'freeWill':    'Free_Will'\n",
    "})\n",
    "\n",
    "# Apply z-standardization of continuous covariates\n",
    "covs = ['Age', 'Political_Orientation', 'Social_Determinism', 'Free_Will']\n",
    "\n",
    "# Ensure numeric types before scaling\n",
    "df_robust[covs] = df_robust[covs].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Apply z-score formula\n",
    "df_robust[[f'{c}_z' for c in covs]] = df_robust[covs].apply(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "print(f\"Transformation complete ({len(df_robust)} Observations).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712fdc6f",
   "metadata": {},
   "source": [
    "# Compare Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4040e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define measures\n",
    "measures = ['measure_action', 'measure_beliefs', 'measure_self']\n",
    "\n",
    "# Run ANOVAs\n",
    "for m in measures:\n",
    "    group_data = [df_long[df_long['Context'] == c][m].dropna() for c in contexts]\n",
    "    f_stat, p_val = stats.f_oneway( * group_data)\n",
    "    print(f\"{m:15}: F = {f_stat:.3f}, p = {p_val:.3f}\")\n",
    "\n",
    "# Create graph\n",
    "df_plot = df_long.rename(columns = labels_measure).melt(id_vars = 'Context', value_vars = labels_measure.values())\n",
    "df_plot['Context'] = df_plot['Context'].str.capitalize()\n",
    "\n",
    "plt.figure(figsize = (10, 6))\n",
    "sns.barplot(data = df_plot,\n",
    "            x = 'variable',\n",
    "            y = 'value',\n",
    "            hue = 'Context',\n",
    "            palette = palette_context,\n",
    "            capsize = .1)\n",
    "\n",
    "# Set style\n",
    "plt.axhline(0, color = 'black', ls = '--', lw = 1)\n",
    "plt.title(\"Comparison of Contexts\")\n",
    "plt.xlabel(\"Variable\")\n",
    "plt.ylabel(\"Value\")\n",
    "\n",
    "# Export graph\n",
    "filename = 'blame_praise_self_experiment_1_contexts.png'\n",
    "plt.savefig(filename, dpi = 300, bbox_inches = 'tight')\n",
    "\n",
    "plt.show()\n",
    "print(f\"Graph saved as '{filename}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15faf450",
   "metadata": {},
   "source": [
    "# Sociodemographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_robust['Gender_Labeled'] = df_robust['Gender'].astype(str).map(labels_gender)\n",
    "df_robust['Education_Labeled'] = df_robust['Education'].astype(str).map(labels_education)\n",
    "\n",
    "for col in ['Gender_Labeled', 'Education_Labeled']:\n",
    "    print(f\"\\n{col}:\")\n",
    "    display(df_robust[col].value_counts().to_frame('Frequency'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f10d25",
   "metadata": {},
   "source": [
    "# Background Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb66b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define background variables\n",
    "background_vars = ['Political_Orientation', 'Social_Determinism', 'Free_Will']\n",
    "\n",
    "# Get summary\n",
    "background_summary = df_robust[background_vars].describe().T[['mean', 'std', 'min', 'max']].round(3)\n",
    "display(background_summary)\n",
    "\n",
    "# Map titles to labels\n",
    "background_titles = {\n",
    "    'Political_Orientation': 'Political Orientation\\n(1 = Liberal, 7 = Conservative)',\n",
    "    'Social_Determinism':    'Social Determinism\\n(1 = Low, 7 = High)',\n",
    "    'Free_Will':             'Free Will\\n(1 = Low, 7 = High)'\n",
    "}\n",
    "\n",
    "# Generate graphs\n",
    "plt.figure(figsize = (18, 5))\n",
    "\n",
    "for i, col in enumerate(background_vars, 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    sns.countplot(data = df_robust, x = col, color = 'salmon', edgecolor = 'black')\n",
    "    \n",
    "    # Set style\n",
    "    plt.title(background_titles[col], fontweight = 'bold', pad = 15)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.ylim(0, df_robust[col].value_counts().max() * 1.1)\n",
    "\n",
    "# Export graphs\n",
    "filename = f'blame_praise_self_experiment_1_background.png'\n",
    "plt.tight_layout()\n",
    "plt.savefig(filename, dpi = 300)\n",
    "plt.show()\n",
    "print(f\"Graph saved as '{filename}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8ac51d",
   "metadata": {},
   "source": [
    "# Calculate Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56040fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define group factors\n",
    "group_factors = ['Upbringing', 'Reflection', 'Belief', 'Action']\n",
    "\n",
    "# Define dependent variables\n",
    "dependent_vars = ['measure_action', 'measure_beliefs', 'measure_self']\n",
    "\n",
    "# Calculate descriptive statistics\n",
    "descriptive_stats = df_long.groupby(group_factors)[dependent_vars].agg(['mean', 'std', 'count']).round(3)\n",
    "\n",
    "# Display results\n",
    "display(descriptive_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3368c099",
   "metadata": {},
   "source": [
    "# Perform ANOVAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f5757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dv in dependent_vars:\n",
    "    \n",
    "    # Print headers\n",
    "    print(f\"\\nANOVA ({labels_measure.get(dv, dv)})\")\n",
    "    \n",
    "    # Define formula\n",
    "    formula = f\"{dv} ~ C(Upbringing) * C(Reflection) * C(Belief) * C(Action) * C(Context)\"\n",
    "    model = ols(formula, data = df_long).fit()\n",
    "    \n",
    "    # Run ANOVAs\n",
    "    aov = sm.stats.anova_lm(model, typ = 2)\n",
    "    \n",
    "    # Calculate effect sizes\n",
    "    aov['partial_eta_sq'] = aov['sum_sq'] / (aov['sum_sq'] + aov.loc['Residual', 'sum_sq'])\n",
    "    \n",
    "    # Rename columns\n",
    "    aov.index.name = 'Source'\n",
    "    aov = aov.rename(columns = {'sum_sq': 'SS', 'df': 'DF', 'PR(>F)': 'p-unc'})\n",
    "    \n",
    "    # Display results\n",
    "    display(aov[['SS', 'DF', 'F', 'p-unc', 'partial_eta_sq']].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc9b40a",
   "metadata": {},
   "source": [
    "# Perform ANCOVAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c727f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define covariates\n",
    "covariates = [\"C(Gender)\", \"Age\", \"C(Education)\", \"Political_Orientation\", \"Social_Determinism\", \"Free_Will\"]\n",
    "\n",
    "for dv in dependent_vars:\n",
    "    \n",
    "    # Print header\n",
    "    print(f\"\\nANCOVA ({labels_measure.get(dv, dv)})\")\n",
    "    \n",
    "    # Define formula\n",
    "    formula = f\"{dv} ~ Upbringing * Reflection * Belief * Action + \" + \" + \".join(covariates)\n",
    "    \n",
    "    model = ols(formula, data = df_robust).fit()\n",
    "    \n",
    "    # Run ANCOVAs\n",
    "    aov_table = sm.stats.anova_lm(model, typ = 2)\n",
    "    \n",
    "    # Calculate effect sizes\n",
    "    res_ss = aov_table.loc['Residual', 'sum_sq']\n",
    "    aov_table['partial_eta_sq'] = aov_table['sum_sq'] / (aov_table['sum_sq'] + res_ss)\n",
    "    \n",
    "    # Rename columns\n",
    "    aov_table = aov_table.rename(columns = {'sum_sq': 'SS', 'df': 'DF', 'PR(>F)': 'p-unc'})\n",
    "    \n",
    "    # Display results\n",
    "    display(aov_table[['SS', 'DF', 'F', 'p-unc', 'partial_eta_sq']].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df00b9a",
   "metadata": {},
   "source": [
    "# Perform Mediation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf55c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mediation(data, x, m, y, seed = 42):\n",
    "    \n",
    "    # Regression M ~ X (path a)\n",
    "    model_m = ols(f\"{m} ~ {x}\", data = data).fit()\n",
    "    path_a = model_m.params[x]\n",
    "    p_a = model_m.pvalues[x]\n",
    "\n",
    "    # Regression Y ~ X + M (path b and direct effect c)\n",
    "    model_y = ols(f\"{y} ~ {x} + {m}\", data = data).fit()\n",
    "    path_b = model_y.params[m]\n",
    "    p_b = model_y.pvalues[m]\n",
    "    path_c_prime = model_y.params[x]\n",
    "    p_c_prime = model_y.pvalues[x]\n",
    "\n",
    "    # Indirect Effect (ab)\n",
    "    indirect_effect = path_a * path_b\n",
    "    \n",
    "    # Create summary tables\n",
    "    results = pd.DataFrame({\n",
    "        'Path': ['a (X -> M)', 'b (M -> Y)', 'Direct (c\\')', 'Indirect (ab)'],\n",
    "        'Coefficient': [path_a, path_b, path_c_prime, indirect_effect],\n",
    "        'p-value': [p_a, p_b, p_c_prime, np.nan]\n",
    "    })\n",
    "    return results\n",
    "\n",
    "# Convert upbringing to binary\n",
    "df_long['Upbringing_bin'] = df_long['Upbringing'].map({'Bad': 0, 'Good': 1})\n",
    "\n",
    "# Run Mediation 1\n",
    "print(\"\\nMediation Analysis: Upbringing -> Beliefs -> Action Evaluation\")\n",
    "med_results_1 = run_mediation(df_long, 'Upbringing_bin', 'measure_beliefs', 'measure_action')\n",
    "display(med_results_1.round(3))\n",
    "\n",
    "# Run Mediation 2\n",
    "print(\"\\nMediation Analysis: Upbringing -> Deep Self -> Action Evaluation\")\n",
    "med_results_2 = run_mediation(df_long, 'Upbringing_bin', 'measure_self', 'measure_action')\n",
    "display(med_results_2.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ff97d5",
   "metadata": {},
   "source": [
    "# Perform LMMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae59503",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hide warnings\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "# Create dictionary\n",
    "models_base = {}\n",
    "\n",
    "# Run LMMs\n",
    "for dv in ['measure_action', 'measure_beliefs', 'measure_self']:\n",
    "    lmm_formula = f\"{dv} ~ Upbringing * Reflection * Belief * Action\"\n",
    "    \n",
    "    # Save in dictionary\n",
    "    models_base[dv] = mixedlm(lmm_formula, data = df_long, groups = df_long[\"Context\"]).fit()\n",
    "    \n",
    "    # Print\n",
    "    print(f\"\\n{labels_measure.get(dv, dv)}\")\n",
    "    print(models_base[dv].summary())\n",
    "\n",
    "# Reset warnings\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642e2b30",
   "metadata": {},
   "source": [
    "# Perform LMMs with Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90169f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hide warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "# Create dictionary\n",
    "models_robust = {}\n",
    "\n",
    "# Define predictors\n",
    "predictors = \"Upbringing * Reflection * Belief * Action\"\n",
    "\n",
    "# Define covariates\n",
    "covariates = \" + C(Gender) + C(Education) + Age_z + Political_Orientation_z + Social_Determinism_z + Free_Will_z\"\n",
    "\n",
    "# Define dependent variables\n",
    "dependent_vars = ['measure_action', 'measure_beliefs', 'measure_self']\n",
    "\n",
    "# Run LMMs with covariates\n",
    "for dv in dependent_vars:\n",
    "    full_formula = f\"{dv} ~ {predictors} + {covariates}\"\n",
    "    \n",
    "    print(f\"\\n{labels_measure.get(dv, dv)}\")\n",
    "    \n",
    "    try:\n",
    "        model = mixedlm(full_formula,\n",
    "                        data = df_robust,\n",
    "                        groups = df_robust[\"Context\"]\n",
    "                       ).fit(method = ['lbfgs'], maxiter = 2000)\n",
    "\n",
    "        # Save in dictionary\n",
    "        models_robust[dv] = model\n",
    "\n",
    "        # Print\n",
    "        print(model.summary())\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating {dv}: {e}\")\n",
    "\n",
    "# Reset warnings\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c605ae",
   "metadata": {},
   "source": [
    "# Compare LMMs with and without Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a79be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dv in dependent_vars:\n",
    "    if dv in models_base and dv in models_robust:\n",
    "        \n",
    "        # Get data\n",
    "        base_params = models_base[dv].params\n",
    "        base_p = models_base[dv].pvalues\n",
    "        robust_params = models_robust[dv].params\n",
    "        robust_p = models_robust[dv].pvalues\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df_comp = pd.DataFrame({\n",
    "            'Base Coef': base_params,\n",
    "            'Robust Coef': robust_params,\n",
    "            'Base p': base_p,\n",
    "            'Robust p': robust_p\n",
    "        }).loc[base_params.index]\n",
    "        \n",
    "        # Set titles\n",
    "        title = labels_measure.get(dv, dv)\n",
    "        print(f\"{title}\")\n",
    "        \n",
    "        # Display tables\n",
    "        display(df_comp.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87019266",
   "metadata": {},
   "source": [
    "# Generate Bar Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45911650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define combinations\n",
    "combinations = [\n",
    "    (\"Upbringing\", \"Reflection\", \"Action\"),\n",
    "    (\"Reflection\", \"Belief\", \"Action\"),\n",
    "    (\"Upbringing\", \"Belief\", \"Action\")\n",
    "]\n",
    "\n",
    "# Create graphs\n",
    "for measure in dependent_vars:\n",
    "    current_label = labels_measure.get(measure, measure)\n",
    "    \n",
    "    for x_var, hue_var, col_var in combinations:\n",
    "        g = sns.catplot(data = df_long,\n",
    "                        x = x_var,\n",
    "                        y = measure,\n",
    "                        hue = hue_var,\n",
    "                        col = col_var,\n",
    "                        kind = \"bar\",\n",
    "                        capsize = .05,\n",
    "                        errorbar = \"ci\",\n",
    "                        palette = palette_main,\n",
    "                        height = 5\n",
    "                       )\n",
    "        \n",
    "        # Set style\n",
    "        x_label_text = f\"{x_var}\"\n",
    "        g.set_axis_labels(x_label_text, \"Mean Score (-6 to +6)\")\n",
    "        g.set_titles(\"{col_name}\")\n",
    "        \n",
    "        g.fig.suptitle(f\"{x_var} × {hue_var} ({current_label})\", y = 1.05, fontsize = 14)\n",
    "        \n",
    "        for ax in g.axes.flat:\n",
    "            ax.axhline(0, color = 'black', linewidth = 1)\n",
    "            ax.set_ylim(-6, 6)\n",
    "        \n",
    "        # Export graphs\n",
    "        filename = f'blame_praise_self_experiment_1_bar_plot_{measure}_{x_var}_{hue_var}.png'.lower()\n",
    "        g.savefig(filename, dpi = 300, bbox_inches = 'tight')\n",
    "        plt.show()\n",
    "        print(f\"Graph saved as '{filename}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb595a5",
   "metadata": {},
   "source": [
    "# Generate Point Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51603a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define interactions\n",
    "interactions = [\n",
    "    (\"Reflection\", \"Belief\", \"Action\"),\n",
    "    (\"Upbringing\", \"Belief\", \"Action\")\n",
    "]\n",
    "\n",
    "# Iterate through dependent variables and interactions\n",
    "for measure in dependent_vars:\n",
    "    current_label = labels_measure.get(measure, measure)\n",
    "    \n",
    "    for x_var, hue_var, col_var in interactions:\n",
    "        \n",
    "        # Create graphs\n",
    "        g = sns.catplot(data = df_long,\n",
    "                        x = x_var,\n",
    "                        y = measure,\n",
    "                        hue = hue_var,\n",
    "                        col = col_var,\n",
    "                        kind = \"point\",\n",
    "                        capsize = .15,\n",
    "                        palette = palette_main,\n",
    "                        height = 5,\n",
    "                        aspect = 1\n",
    "                       )\n",
    "        \n",
    "        # Set axis labels and titles\n",
    "        g.set_axis_labels(x_var, f\"{current_label}\")\n",
    "        g.set_titles(\"{col_name}\")\n",
    "        \n",
    "        # Add main titles\n",
    "        g.fig.suptitle(f\"{x_var} × {hue_var} ({current_label})\", y = 1.05, fontsize = 14)\n",
    "        \n",
    "        # Format axes\n",
    "        for ax in g.axes.flat:\n",
    "            \n",
    "            # Add horizontal zero lines\n",
    "            ax.axhline(0, color = 'black', linewidth = 1, linestyle = '--', alpha = 0.5)\n",
    "            \n",
    "            # Set scale limits\n",
    "            ax.set_ylim(-6, 6)\n",
    "        \n",
    "        # Export graphs\n",
    "        filename = f'blame_praise_self_experiment_1_interaction_plot_{measure}_{x_var}_{hue_var}.png'.lower()\n",
    "        g.savefig(filename, dpi = 300, bbox_inches = 'tight')\n",
    "        plt.show()\n",
    "        print(f\"Graph saved as '{filename}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913f29ea",
   "metadata": {},
   "source": [
    "# Generate Violin Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3b19bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape DataFrame from wide to long for categorical plotting\n",
    "df_melted = df_long.melt(id_vars = ['Action', 'Upbringing', 'Reflection', 'Belief', 'Context'],\n",
    "                         value_vars = dependent_vars, var_name = 'Measure', value_name = 'Score')\n",
    "\n",
    "# Map measures to labels\n",
    "df_melted['Measure'] = df_melted['Measure'].replace({\n",
    "    'measure_action':  'Responsibility for Action',\n",
    "    'measure_beliefs': 'Responsibility for Character',\n",
    "    'measure_self':    'True Self'\n",
    "})\n",
    "\n",
    "# Map factors to color palettes\n",
    "dimensions = [\n",
    "    ('Upbringing', palette_main),\n",
    "    ('Reflection', palette_main),\n",
    "    ('Action',     palette_main),\n",
    "    ('Belief',     palette_main)\n",
    "]\n",
    "\n",
    "# Create graphs\n",
    "for factor_name, palette in dimensions:\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    \n",
    "    # Split violins\n",
    "    sns.violinplot(data = df_melted, x = \"Measure\", y = \"Score\", hue = factor_name,\n",
    "                   split = True, inner = \"quart\", palette = palette)\n",
    "    \n",
    "    # Set style\n",
    "    plt.axhline(0, color = 'black', linewidth = 1, linestyle = '--')\n",
    "    plt.title(f\"{factor_name}\", fontsize = 14)\n",
    "    plt.ylim(-7, 7)\n",
    "    \n",
    "    # Export graphs\n",
    "    filename = f'blame_praise_self_experiment_1_violin_plot_{factor_name}.png'.lower()\n",
    "    plt.savefig(filename, dpi = 300, bbox_inches = 'tight')\n",
    "    print(f\"Graph saved as '{filename}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
